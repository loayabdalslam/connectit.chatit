from __future__ import annotations
import asyncio
import json
import platform
import psutil
import websockets
from typing import Dict, Any, Optional

from .protocol import (
    msg,
    REGISTER,
    HEARTBEAT,
    TASK,
    RESULT,
    ERROR,
    INFO,
    TASK_LAYER_FORWARD,
    TASK_LAYER_FORWARD_TRAIN,
    TASK_LAYER_BACKWARD,
    HF_LOAD,
    HF_UNLOAD,
    HF_INFER,
    ONNX_LOAD,
    ONNX_UNLOAD,
    ONNX_INFER,
)
from .model import deserialize_layer, layer_forward
from .utils import new_id
import numpy as np


def gather_resources() -> Dict[str, Any]:
    mem = psutil.virtual_memory()
    return {
        "os": platform.system(),
        "cpu_count": psutil.cpu_count(logical=True),
        "memory_gb": round(mem.total / (1024**3), 2),
        "gpu": False,  # TODO: detect GPU
    }


async def node_client(coordinator_url: str, node_name: Optional[str], price: float = 0.0):
    node_id: Optional[str] = None
    # Optional PyTorch support
    try:
        import torch  # type: ignore
        HAS_TORCH = True
        DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    except Exception:  # pragma: no cover
        torch = None  # type: ignore
        HAS_TORCH = False
        DEVICE = "cpu"

    caches: dict[str, dict[str, Any]] = {}
    models: dict[str, Any] = {}  # model_id -> {'type': 'hf'|'onnx', 'obj': model, 'tokenizer': tok, 'device': dev}
    while True:
        try:
            async with websockets.connect(coordinator_url, max_size=32 * 1024 * 1024) as ws:
                # Register
                await ws.send(
                    json.dumps(
                        msg(
                            REGISTER,
                            node_id=new_id("node"),
                            name=node_name or platform.node(),
                            resources=gather_resources(),
                            price=price,
                        )
                    )
                )
                # Main loop
                async for raw in ws:
                    try:
                        data = json.loads(raw)
                    except Exception:
                        continue
                    t = data.get("type")
                    if t == INFO and not node_id:
                        node_id = data.get("node_id")
                    elif t == TASK:
                        task_id = data.get("task_id")
                        payload = data.get("payload", {})
                        try:
                            kind = payload.get("kind")
                            if kind == TASK_LAYER_FORWARD:
                                layer = deserialize_layer(payload["layer"])
                                x = np.array(payload["x"], dtype=np.float32)
                                y = layer_forward(layer, x)
                                await ws.send(json.dumps(msg(RESULT, task_id=task_id, output=y.tolist())))
                            elif kind == TASK_LAYER_FORWARD_TRAIN:
                                cache_id = payload.get("cache_id")
                                layer = deserialize_layer(payload["layer"])
                                x = np.array(payload["x"], dtype=np.float32)
                                # Compute forward and store caches (x, z)
                                z = x @ layer.W + layer.b
                                if HAS_TORCH:
                                    # Use torch for activation if available
                                    import torch  # type: ignore
                                    xt = torch.from_numpy(x).to(DEVICE)
                                    Wt = torch.from_numpy(layer.W).to(DEVICE)
                                    bt = torch.from_numpy(layer.b).to(DEVICE)
                                    zt = xt @ Wt + bt
                                    if layer.activation == "relu":
                                        yt = torch.nn.functional.relu(zt)
                                    elif layer.activation == "gelu":
                                        yt = torch.nn.functional.gelu(zt)
                                    else:
                                        yt = zt
                                    y = yt.detach().cpu().numpy()
                                else:
                                    from .model import act
                                    y = act(z, layer.activation)
                                if cache_id:
                                    caches[str(cache_id)] = {
                                        "x": x,
                                        "z": z,
                                        "activation": layer.activation,
                                        "W": layer.W,
                                        "b": layer.b,
                                    }
                                await ws.send(json.dumps(msg(RESULT, task_id=task_id, output=y.tolist())))
                            elif kind == TASK_LAYER_BACKWARD:
                                cache_id = payload.get("cache_id")
                                up = np.array(payload["upstream_grad"], dtype=np.float32)
                                entry = caches.pop(str(cache_id), None)
                                if entry is None:
                                    raise RuntimeError("missing_cache")
                                x = entry["x"]
                                z = entry["z"]
                                W = entry["W"]
                                b = entry["b"]
                                act_kind = entry["activation"]
                                # Compute grads
                                if HAS_TORCH:
                                    import torch  # type: ignore
                                    xt = torch.from_numpy(x).to(DEVICE)
                                    Wt = torch.from_numpy(W).to(DEVICE)
                                    bt = torch.from_numpy(b).to(DEVICE)
                                    zt = xt @ Wt + bt
                                    if act_kind == "relu":
                                        yt = torch.nn.functional.relu(zt)
                                        dz = (zt > 0).to(zt.dtype)
                                    elif act_kind == "gelu":
                                        yt = torch.nn.functional.gelu(zt)
                                        # approximate derivative via autograd on zt requires graph; do manual approx
                                        c = (2 / np.pi) ** 0.5
                                        t = torch.tanh(torch.tensor(c, device=zt.device, dtype=zt.dtype) * (zt + 0.044715 * (zt ** 3)))
                                        dz = 0.5 * (1 + t) + 0.5 * zt * (1 - t ** 2) * torch.tensor(c, device=zt.device, dtype=zt.dtype) * (1 + 0.134145 * (zt ** 2))
                                    else:
                                        dz = torch.ones_like(zt)
                                    up_t = torch.from_numpy(up).to(DEVICE)
                                    gz = up_t * dz
                                    gW = xt.transpose(0, 1) @ gz
                                    gb = torch.sum(gz, dim=0)
                                    gX = gz @ Wt.transpose(0, 1)
                                    await ws.send(
                                        json.dumps(
                                            msg(
                                                RESULT,
                                                task_id=task_id,
                                                dX=gX.detach().cpu().numpy().tolist(),
                                                gW=gW.detach().cpu().numpy().tolist(),
                                                gb=gb.detach().cpu().numpy().tolist(),
                                            )
                                        )
                                    )
                                else:
                                    from .model import act_derivative
                                    dz = up * act_derivative(z, act_kind)
                                    gW = x.T @ dz
                                    gb = dz.sum(axis=0)
                                    gX = dz @ W.T
                                    await ws.send(json.dumps(msg(RESULT, task_id=task_id, dX=gX.tolist(), gW=gW.tolist(), gb=gb.tolist())))
                            else:
                                await ws.send(json.dumps(msg(ERROR, task_id=task_id, error=f"unknown_task:{kind}")))
                        except Exception as e:
                            await ws.send(json.dumps(msg(ERROR, task_id=task_id, error=str(e))))
                    elif t == TASK:
                        pass
                    else:
                        pass
        except Exception:
            await asyncio.sleep(2)
            continue
        # Outer try ends, reconnect
        
                    else:
                        # ignore
                        pass
        except Exception:
            await asyncio.sleep(2)


def run_node(coordinator_url: str, node_name: Optional[str], price: float = 0.0):
    asyncio.run(node_client(coordinator_url, node_name, price))

